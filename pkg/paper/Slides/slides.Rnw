\documentclass[11pt,compress,t]{beamer}
\usetheme{Z}
\usepackage{amsfonts,amstext,amsmath}
\usepackage{longtable}
\usepackage{multirow}

%% need no \usepackage{Sweave}


\setkeys{Gin}{width=\textwidth}
\SweaveOpts{engine=R, eps=FALSE, echo=FALSE, results=hide, keep.source=TRUE}



<<preliminaries>>=
## packages
if(Sys.getlocale() != "C") Sys.setlocale("LC_TIME", "English")
library("glogis")
library("fxregime")
library("lattice")

## additional functions
moments <- function(object, ...) UseMethod("moments")
moments.glogisfit <- function(object, ...) object$moments
moments.breakpoints.glogisfit <- function(object, breaks = NULL, ...)
  t(sapply(refit(object, breaks = breaks), "[[", "moments"))
  
## For the creation of the tables
root_dir <- do.call("file.path", as.list(head(strsplit(getwd(), .Platform$file.sep)[[1]], -1)))
setwd(file.path(root_dir, "Analysis"))
fnam <- Sys.glob("*.rda")
if(!file.exists("Austria.rda")) Sweave("results.Rnw")
setwd(file.path(root_dir, "Slides"))

## query result file names
## fixed file path
fnam2 <- grep("2", fnam, fixed = TRUE)
if(length(fnam2) > 0) fnam <- fnam[-fnam2]

## set up named results list
results <- vector(length = length(fnam), mode = "list")
names(results) <- sapply(strsplit(sapply(strsplit(fnam, "/", fixed = TRUE), tail, 1), ".", fixed = TRUE), head, 1)

## erm <- yearmon(c(
##   Austria = 1995,
##   ...,
##   France = 1995 + 1/12,
##   ...))

## create erm (Exchange rate mechanism bzw. exchange rate mechanism 2
## ERM~II, ERM~I (part of european monetary system expired in 1.1.1999 gave way to ERM II
## if never entered ""right?
## http://web.archive.org/web/20080101022356/http://lexikon.meyers.de/meyers/Europ%C3%A4isches_W%C3%A4hrungssystem

erm <- yearmon(c(
	Austria = 1995,
	Belgium = 1979 + 2/12,
	CzechRepubic = NA, 
	Denmark = 1979 + 2/12,
	Estonia = NA,
	Finland = 1996 + 9/12,
	France = 1979 + 2/12,
	Germany = 1979 + 2/12,
	Greece = 1998 + 2/12,
	Hungary = NA,
	Ireland = 1979 + 2/12,
	Italy = 1979 + 2/12,
	Luxembourg = 1979 + 2/12,
	Netherlands = 1979 + 2/12,
	Poland = NA,
	Portugal = 1992 + 3/12,
	Slovakia = NA,
	Slovenia = NA,
	Spain = 1986 + 5/12,
	Sweden = NA ,
	UnitedKingdom = NA
))

erm2 <- yearmon(c(
	Austria = NA,
	Belgium = NA,
	CzechRepubic = NA, 
	Denmark = 1999,
	Estonia = 2004 + 5/12,
	Finland = NA,
	France = NA,
	Germany = NA,
	Greece = 1999,
	Hungary = NA,
	Ireland = NA,
	Italy = NA,
	Luxembourg = NA,
	Netherlands = NA,
	Poland = NA,
	Portugal = NA,
	Slovakia = 2005 + 10/12,
	Slovenia = 2004 + 5/12,
	Spain = NA,
	Sweden = NA ,
	UnitedKingdom = NA
))

eur <- yearmon(c(
	Austria = 1999,
	Belgium = 1999,
	CzechRepubic = NA, 
	Denmark = NA,
	Estonia = 2011,
	Finland = 1999,
	France = 1999,
	Germany = 1999,
	Greece = 2001,
	Hungary = NA,
	Ireland = 1999,
	Italy = 1999,
	Luxembourg = 1999,
	Netherlands = 1999,
	Poland = NA,
	Portugal = 1999,
	Slovakia = 2009,
	Slovenia = 2007,
	Spain = 1999,
	Sweden = NA ,
	UnitedKingdom = NA
))


## sequentially load data
for(i in seq_along(fnam)) {
  load(file.path(root_dir, "Analysis", fnam[i]))
  results[[i]] <- list(
    data = x,
    model0 = x_gf,
    efp = x_efp,
    nbreaks = x_nbreaks,
    breakpoints = x_bp,
    model = x_rf,
    erm = erm[i],
    erm2 = erm2[i],
    eur = eur[i])
}

## compute moments
mom <- lapply(results, function(obj) t(sapply(obj$model, moments)))

## LaTeX formatting
format_moments <- function(i, digits = 3) {
  rval <- format(round(mom[[i]], digits = digits), nsmall = digits)
  #rval <- cbind("", rownames(rval), matrix(paste("$", rval, "$", sep = ""), ncol = 3), "", "", "")
  rval <- cbind("", rownames(rval), matrix(paste("$", rval, "$", sep = ""), ncol = 3))
  rval[1,1] <- if(is.character(i)) i else names(mom)[i]
  #rval[1,6] <- if(is.na(results[[i]]$erm)) "--" else format(results[[i]]$erm)
  #rval[1,7] <- if(is.na(results[[i]]$erm2)) "--" else format(results[[i]]$erm2)
  #rval[1,8] <- if(is.na(results[[i]]$eur)) "--" else format(results[[i]]$eur)
  rval <- apply(rval, 1, paste, collapse = " & ")
  rval <- paste(rval, "\\\\")
  rval[length(rval)] <- paste(rval[length(rval)], "\\hline")
  return(rval)
}

xyplot.gefp <- function(x, panel = NULL, ylim = NULL, ...)
{
  cval <- maxBB$computeCritval(0.05, ncol(x$process))
  if(is.null(ylim)) ylim <- range(c(range(x$process), 1.1 * cval, -1.1 * cval)) 

  gefp_plot <- function(x, y, subscripts, groups, panel = panel.xyplot,
    col = 1, type = "p", pch = 20, lty = 1, lwd = 1, ...)
  {
    col <- rep(as.list(col), length = nlevels(groups))
    type <- rep(as.list(type), length = nlevels(groups))
    pch <- rep(as.list(pch), length = nlevels(groups))
    lty <- rep(as.list(lty), length = nlevels(groups))
    lwd <- rep(as.list(lwd), length = nlevels(groups))

    for(g in 1:nlevels(groups)) {
      idx <- levels(groups)[g] == groups[subscripts]
      if (any(idx)) panel(x[idx], y[idx], ...,
        col = col[[g]], type = type[[g]], pch = pch[[g]],
        lty = lty[[g]], lwd = lwd[[g]])
      grid::grid.lines(y = grid::unit(0, "native"))
      grid::grid.lines(y = grid::unit(cval, "native"), gp = grid::gpar(col = 2))
      grid::grid.lines(y = grid::unit(-cval, "native"), gp = grid::gpar(col = 2))
    }
  }
  if(is.null(panel)) panel <- gefp_plot
  
  xyplot(x$process, panel = panel, ylim = ylim, ...)
}


## data
data("HICP", package = "glogis")
HICP <- HICP[, colnames(HICP) != "EU"]
@


\begin{document}


\title{Structural Breaks in Inflation Dynamics within the European Monetary Union}
\author{Thomas Windberger, Achim Zeileis}
\URL{http://glogis.R-Forge.R-project.org/}
\lecture{Structural Breaks in Inflation Dynamics within the European Monetary Union}


\subsection{Overview}

\begin{frame}
\frametitle{Overview}

\begin{itemize}
  \item Introduction and Data
%  \begin{itemize}
%    \item HICP
%  \end{itemize}
  \item Model
%    \begin{itemize}
%    \item GL-Distribution
% 		\end{itemize}
  \item Example
  \item Results
  \item Conclusion
\end{itemize}


\end{frame}

\subsection{Introduction}

\begin{frame}
\frametitle{Introduction and Data}


\begin{itemize}
  \item Did European Monetary Union (EMU) change inflation dynamics?
  \item Economic reasons
  	\begin{itemize}
  	\item Former Council for Mutual Economic Assistance (COMECON) member states
  	% abkürzung für: Council for Mutual Economic Assistance
  	% stabilise inflation for EURO introduction or ERM II entry
  	\item Ex-Yugoslavia countries
  	% same as former comecon countries 
  	\item Southern European countries
  	% profit from a more credible central bank which is more inclined towards price stability
  	\item Central European countries
  	% not that clear cut evidence; if previous central bank was hawkish towards inflation doubtful that we would find a lot of change
  	% theory does not know for certain what would happen --> very dependend upon parameterization in the model (for example \cite{holte}
  	\end{itemize}
% former high inflation country now lower, imports credibility  
% monetary discipline for new EURO countries like Estonia, Slovenia...
% differences still have to remain \cite{duarte}, ECB stabilises the global inflation rate, no more power to focus on some nation
  \item Harmonised Index of Consumer Prices (HICP) for 21 countries. Monthly unadjusted data up to March~2010
  \item Source: OECD Statistics
	\item 3 groups
		\begin{itemize}
		\item EURO countries
		\item EU members without Exchange Rate Mechanism~II (ERM~II) 
		% like Sweden, UK, poland, czech republic, Hungary, Romania, Bulgaria
		\item ERM~II countries
		% Denmark: ERM~II but not EURO, Estonia, Latvia, Lithuania
		\end{itemize}
\end{itemize}
\end{frame}


\subsection{Model}
\begin{frame}
\frametitle{Model}

\begin{itemize}
\item Our approach:
	\begin{itemize}
	\item Track evolution of distribution over time for each country
	\item Investigate changes in mean, variance, and skewness over time
	\item Idea: Identify changes associated with interventions, crises, etc.
	% not a problem with correlation of series, no change if estimated with HAC (heteroscedasticity and autocorrelation adjusted estimator)
	\end{itemize}
	% talk about multivariate models like the one from palomba with inflation convergence etc.
\item Of less interest in this analysis:
	\begin{itemize}
	\item Correlation over time (e.g., ARIMA, GARCH)
	\item Correlation between countries (e.g., VAR)
	% multivariate like palombas
	% then test for a breakpoint in the parameters
	% which does not work for short time series and it is doubtful if there are any effects
	% also: arima and garch test for a corelation structure
	% generalized autoregressive conditional heteroscedasticity
	\end{itemize}
\item Selected method:
	\begin{itemize}
	\item Maximum likelihood for flexible distribution: Generalized logistic distribution allowing
	for fat tails, and potential skewness
	\item Testing and dating of structural breaks
	\item Neglect correlation structure or treat as nuisance parameter
	\end{itemize}
\end{itemize}


\end{frame}


\begin{frame}
\frametitle{Generalized Logistic (GL) Distribution}

For return series $y_t = 100\cdot log(HICP_t/HICP_{t-1})$ ($t = 1, \dots, n$) we assume a GL distribution given by:

\begin{eqnarray}
f(y | \theta, \sigma, \delta) & = & \frac{\frac{\delta}{\sigma} \cdot \exp^{-\frac{y-\theta}{\sigma}}}{(1+\exp^{-\frac{y-\theta}{\sigma}})^{(\delta+1)}} \nonumber
\end{eqnarray}

with location $\theta$, scale $\sigma$ and shape $\delta$. \\

% For $\delta=1$ the distribution simplifies to the logistic distribution, for $\delta < 1$ it is skewed to the left and for $\delta > 1$ it is skewed to the right. 
% Regress+ Appendix A  Compendium of Common Probability Distributions 
% as a explanation why to use the GL-distribution

Moments:

% quelle: dp02_15.pdf 
% Paper: ML-Estimation in the Location-Scale-Shape Model of the Generalized Logistic Distribution
\begin{eqnarray}
E(y) & = & \theta + \sigma(\psi(\delta) - \psi(1)) \nonumber \\
VAR(y) & = & \sigma^2(\psi'(1)+\psi'(\delta)) \nonumber \\
SKEW(y) & = & \frac{\psi''(\delta) - \psi''(1)}{(\psi'(1)+\psi'(\delta))^\frac{3}{2}} \nonumber  
\end{eqnarray}
% where \psi is the digamma function Gamma'(b)/Gamma(b) and its derivatives  
\end{frame}


\begin{frame}
\frametitle{Framework}
% before starting  give motivation:
%1. choose appropriate estimation technique (ML) and its score function
%2. empirical partial sum process (efp) used to capture instabilities (efp governed by FCLT)
%3. measure fluctuation within process by a scalar functional yielding some test statistic (like supLM)
%4. then breakpoint selection
% under parameter stability the scores have 0 mean 

Assuming $\phi = (\theta, \sigma, \delta)$ is stable over time $t$, it
can be estimated by maximum likelihood, or equivalently solving the estimating equations:
\begin{eqnarray}
& \hat{\phi} ~=~ \underset{\phi}{argmax} \sum_{t=1}^n \log f(y_t|\phi), \nonumber\\
& \sum_{t=1}^n s(y_t|\hat{\phi}) ~=~ 0, \nonumber
\end{eqnarray}

\medskip

Question: Is the assumption valid or do the $\phi_t$ vary over time?
% under parameter stability
\begin{eqnarray}
& H_0: \phi_t = \phi_0 \quad (t=1,...,n) \nonumber 
%\end{eqnarray}
%
%% parameters estimated by ML 
%
%\begin{eqnarray}
\end{eqnarray}

This can be assessed using the empirical scores $s(y_t|\hat{\phi})$ as
measures of model deviation.
% then we can apply a CLT (central limit theorem)

%Under certain assumptions, a central limit theorem holds:
%% for details: Z2010 S.1698
%\begin{eqnarray}
%\sqrt{n}(\hat{\psi}) \overset{d}{\rightarrow} \mathcal{N}(0,A_0^{-1} B_0 A_0^{-1}), \nonumber \\
%%A_0 = plim \; n^{-1} \sum_{t=1}^n E[-s'(y_t,\psi_0)], \nonumber \\
%%B_0 = plim \; n^{-1} \sum_{t=1}^n VAR[-s(y_t,\psi_0)] \nonumber
%\end{eqnarray}
%where $\psi'$ is the derivative of $\psi$, again with respect to $\theta$. 
\end{frame}

\begin{frame}
% then we want to know if there is some change in our distribution via variations in the scores
\frametitle{Scores}

Score function has 3 components $(s_{\theta}, s_{\sigma}, s_{\delta})$, with $\tilde{y} = \exp^{-\frac{y-\theta}{\sigma}}$
% for the parameters (the derivatives of the log-likelihood) 
% scores given in dp02_15 p.14

\small
\begin{align}
s_{\theta}(y|\theta, \sigma, \delta) & =  \frac{\delta \log f(y|\theta,\sigma, \delta)}{\delta \theta}  \nonumber \\
&=  \frac{1}{\sigma} - (\delta+1)\cdot\frac{\frac{1}{\sigma}\tilde{y}}{(1+\tilde{y})}  \nonumber \\
s_{\sigma}(y|\theta, \sigma, \delta) & =  \frac{\delta \log f(y|\theta,\sigma, \delta)}{\delta \sigma} \nonumber  \\
& =  -\frac{1}{\sigma} + \frac{1}{\sigma^2}(y-\theta) - (\delta+1) \times \frac{\frac{1}{\sigma^2}(y-\theta)\tilde{y}}{(1+\tilde{y})} \nonumber \\
%\end{eqnarray}
%
%\begin{eqnarray}
s_{\delta}(y|\theta, \sigma, \delta) & =  \frac{\delta \log f(y|\theta,\sigma, \delta)}{\delta \delta} \nonumber \\
& =   \frac{1}{\delta} - \log(1+\tilde{y}) \nonumber 
\end{align}
% where loglik is the log-likelihood of y
\end{frame}


\begin{frame}
\frametitle{Empirical Fluctuation Process}
% t in there: is reskaliert: floor(i/n), läuft immer von 0-1; bei 1 muss der Prozess wieder auf 0 enden (daher immer so bogenmässige form)
% decorrelation throught V^-1/2 
% 3d BB: 3*n matrix; brownsche brücke: geht zu t=1 auf 0 zurück, als nebenbedingung 
% similar to a cumulated sum of residuals
% view as cumulative deviations where we are able to get test values 
The empirical fluctuation process $\mathit{efp}(\cdot)$ captures systematic deviations from zero over time:

\begin{eqnarray}
\mathit{efp}(t) ~=~ \hat{V}^{-1/2} n^{-1/2} \sum_{i=1}^{\lfloor nt \rfloor} s(y_i|\hat{\theta}, \hat{\sigma}, \hat{\delta}) \quad (0 \leq t \leq 1), \nonumber
\end{eqnarray}

% with W^0 beeing a 3-dimensional brwonian motion W^0(t() = W(t) - tW(1)
% brownian motion: zeitstetiger stochastischer Prozess, der normalverteilte, unabhängige Zuwächse E(W) = 0, Var=t; W(t) ~ N(0,t)

\medskip

Functional central limit theorem (FCLT) for $\mathit{efp}(\cdot)$:
converges to a 3-dimensional Brownian bridge:

\begin{eqnarray}
\mathit{efp}(\cdot) ~\overset{d}{\rightarrow}~ W^0(\cdot) \nonumber
\end{eqnarray}


\end{frame}


\begin{frame}
\frametitle{Test}

$\mathit{efp}(\cdot)$ could be aggregated to test statistic in various ways.

\medskip

Here: Employ Andrews' sup$LM$ test
% aggregates values at te times t=1,2,....,n
% explain with the graphics that shows residuals very clearly

\begin{eqnarray}
\underset{t \in [0.1, 0.9]}{sup} \frac{\Vert \mathit{efp}(t) \Vert_2^2}{t(1-t)} \nonumber
\end{eqnarray}

% optimal to test for a singel abrupt change of unknown timing
% reject when fluctuation of the empirical process becomes improbably large compared to the fluctuation of the limiting process (i.e. when boundaries are crossed)

\medskip

p-values can be computed from:

\begin{eqnarray}
\underset{t \in [0.1, 0.9]}{sup} \frac{\Vert W^0(t) \Vert_2^2}{t(1-t)} \nonumber
\end{eqnarray}

% with W^0 beeing a 3-dimensional brwonina motion W^0(t() = W(t) - tW(1)
% brownian motion: zeitstetiger stochastischer Prozess, der normalverteilte, unabhängige Zuwächse E(W) = 0, Var=t; W(t) ~ N(0,t)
% goodness of fit test H0 is not rejected 23-21 (44 periods in total) times, ie. in 52% of the cases

\end{frame}


\begin{frame}
\frametitle{Breakpoint Estimation}

% step by step:
%1. choose m, the number of breaks (if suggested by supLM test , m=1 or higher)
%2. minimize the log-likelihood function by segmenting in a way to minimize the sum of the log-likelihoods
%3. save penalty terms 
%4. increase m and do steps 2-3 once more
%5. choose m with the best LWZ value (which is a modified BIC) 0.299*log(n)^2.1 (p.1701 Z(2010)); the lower the value the better the model
%there is a minimal distance of h=24 between breakpoints
% computation becomes burdensome (of order O(n-2*h)^m, ie. h is minimum size of segment, m is number of breakpoints with n=200 and m=1 and h=24, 152 possible breakpoints)
% but there exists an algorithm of Bai and Perron that decreases computational burden (Z2010, p.1700f)


% if instability is detected, natural to ask when
% assumge segments in data, that are stable but change with every segment
If instability detected, estimate $B$ breakpoints $\tau_1,...,\tau_B$ via maximization of full segmented likelihood:
% partial since this is the log-likelihood for the specific time frame
\begin{eqnarray}
% \sum_{b=1}^B \sum_{t=\tau_{(b-1)}}^{\tau_b} loglik (y_t | \theta^{(b)}, \sigma^{(b)}, \delta^{(b)}) \nonumber
% if m = 1 and n = 200, we have \tau_0= 0, \tau_1 = 100, \tau_2 = n
% have to introduce \tau_0 = 0 and \tau_b+1 = n
\sum_{b=1}^{B+1} \sum_{t=\tau_b + 1}^{\tau_b} \log f(y_t | \phi^{(b)}) \nonumber
\end{eqnarray}

\medskip

All parameters $\tau_1, \dots, \tau_B, \phi^{(1)}, \dots, \phi^{(B+1)}$ can be estimated jointly
using dynamic programming.

\medskip

Model selection: Select best $B$ via a modified BIC from fitted models for $B = 1, \dots, 6$.

% BIC: log(n) is the penalty term; in modified LWZ: 0.299*log(n)^2.1 (p.1701 Z(2010))
% all breakpoints and all segments are simultaneously estimated

% search over all conceivable partitions can be cut shortly applying Bellman principle 
% with systemspecific parameters \theta^{(b)}, \sigma^{(b)}, \delta^{(b) and breakpoints \tau_1,...\tau_B
% simultaneously estimated
% minimal segment size is 2 years = 24 observations

\end{frame}


\subsection{Example}

\begin{frame}
\frametitle{Slovenia: Data}

\vspace*{-0.9cm}

\begin{center}
<<fig=TRUE, height=4, width=8>>=
x <- results$Slovenia
plot(x$data, xlab = "Time", ylab = "100 * diff(log(HICP))", main = "")
@
\end{center}

\vspace*{-0.5cm}

{
\small \color{white}
\begin{longtable}{llrrr}
\hline
Country & Segment & Mean & Variance & Skewness  \\
\hline
<<echo=FALSE, results=tex>>=
writeLines(unlist(lapply(c(18), format_moments)))
@
\end{longtable}
}

\end{frame}


\begin{frame}
\frametitle{Slovenia: Fitted Model}

\vspace*{-0.9cm}

\begin{center}
<<fig=TRUE, height=4, width=8>>=
plot(x$data, xlab = "Time", ylab = "100 * diff(log(HICP))", main = "")
lines(x$breakpoints, breaks = x$nbreaks)
lines(fitted(x$breakpoints, breaks = x$nbreaks, type = "mean"), col = 4)
@
\end{center}

\vspace*{-0.5cm}

{
\small
\begin{longtable}{llrrr}
\hline
Country & Segment & Mean & Variance & Skewness  \\
\hline
<<echo=FALSE, results=tex>>=
writeLines(unlist(lapply(c(18), format_moments)))
@
\end{longtable}
}

\end{frame}


\begin{frame}
\frametitle{Slovenia: Test}
% the line is at the point where the LR ratio is maximal, but we estimate LM and LM is converging to LR asympotically

\vspace*{-0.9cm}

\begin{center}
<<fig=TRUE, height=4, width=8>>=
plot(x$efp, functional = supLM(0.1), main = "supLM test", xaxt = "n", xlim = range(time(x$data)))
Axis(time(x$data), side = 1)
lines(x$breakpoints, breaks = x$nbreaks)
@

\vspace*{-0.5cm}

{
\small \color{white}
\begin{longtable}{llrrr}
\hline
Country & Segment & Mean & Variance & Skewness  \\
\hline
<<echo=FALSE, results=tex>>=
writeLines(unlist(lapply(c(18), format_moments)))
@
\end{longtable}
}

\end{center}
\end{frame}


\begin{frame}
\frametitle{Slovenia: Moment Changes}
% for a better understanding of the sources of the change (change in shape means that it is now less skewed to the right, so inflation is lower)
% the lines are the max of the absolute value; 1. aggregate over time, 2. aggregate over components
% "C:\Program Files\R\R-2.11.1-x64\bin\Rgui.exe
% change languate to english: Sys.setlocale("LC_TIME", "English")

\vspace*{-0.9cm}

<<fig=TRUE, height=5.5, width=7>>=
trellis.par.set(theme = standard.theme(color = FALSE))
print(xyplot(x$efp, aggregate = FALSE, ylim = c(-2.2, 2.2)))
@
% careful: the red lines are the doppelmax statistics not the supLM (just dont mention it:) 
% doppelmax given by: max_i=1...n max_j=1...k |\mathit{efp}_j(i/n))| ; i.e. aggregated over both time and components
\end{frame}

%
%\begin{frame}
%\frametitle{Goodness of fit Test}
%
%<<fig=TRUE, height=4.5, width=9>>=
%<<plot3>>
%@
%% only if enough time
%\end{frame}
\begin{frame}
\frametitle{Slovenia: Breakpoint Selection}

\vspace*{-0.4cm}

<<slovbpsel, fig=TRUE, height=5.5, width=8>>=
plot(x$breakpoints)
@
\end{frame}


\begin{frame}
\frametitle{Slovenia: Fitted Model}

Economic Interpretation: 

\begin{itemize}
\item had to reach Maastricht criteria 
	\begin{itemize}
	\item low inflation rate ($<1.5$ percentage points higher than average of 3~best performing)
	\item deficit no higher than 3\% of GDP
	\item gross government debt $<60\%$ of GDP
	\item no devaluation in ERM~II
	\end{itemize}
%  Inflation rates: No more than 1.5 percentage points higher than the average of the three best performing (lowest inflation) member states of the EU.
%  The ratio of the annual government deficit to gross domestic product (GDP) must not exceed 3% at the end of the preceding fiscal year. If not, it is at least required to reach a level close to 3%.
% The ratio of gross government debt to GDP must not exceed 60% at the end of the preceding fiscal year
%  Exchange rate: Applicant countries should have joined the exchange-rate mechanism (ERM II) under the European Monetary System (EMS) for two consecutive years and should not have devalued its currency during the period.
% Long-term interest rates: The nominal long-term interest rate must not be more than 2 percentage points higher than in the three lowest inflation member states.
\item most reforms regarding financial sector introduced in 2003
\item strong contraction in money supply (M1) starting in 2003 
% search for good explanations, why variance is always higher 
\item from 2003 onwards much lower mean, but higher variance
\item entered ERM~II in June 2004; declared ready to join by ECB  in May 2006
% http://ec.europa.eu/economy_finance/focuson/focuson9120_en.htm
\end{itemize}
\end{frame}



\subsection{Results}
\begin{frame}
\frametitle{Results}

% in subgropus and only some for presentation
Some countries follow very similar patterns

\begin{itemize}
\item Eastern countries: Czech Republic, Estonia, Hungary, Poland and possibly Slovakia 
% mean and var decline end of 90s start of 00s
% extreme skewness in case of Slovakia
\item Belgium and Luxembourg
% strong increase in variance in 99, 00
\item Italy and Spain
% almost identical 
\item Ireland
% finacial crisis
\item No change countries: Finland, Greece, Netherlands
\item Further results
\end{itemize}
\end{frame}

% show only these countries
% show table and explain 2,3 things per table --> hypothesis for similar behavior
% 4 folias: bel, lux --> ita, spa --> ireland --> no change wiht emphasis on greece


\begin{frame}
\frametitle{Belgium and Luxembourg}
% could be looking much better

\vspace*{-0.8cm}

\begin{center}
<<bellux, fig=TRUE, height=5, width=8>>=
trellis.par.set(theme = standard.theme(color = FALSE))
print(xyplot(cbind(100*diff(log(na.omit(HICP[, "Belgium"]))), 100*diff(log(na.omit(HICP[, "Luxembourg"])))), xlab="Time", ylab="", main="", screens=list("Belgium", "Luxembourg")), ylim=c(-2,2))
@
\end{center}
\end{frame}

\begin{frame}
\frametitle{Belgium and Luxembourg}

% get rid of ERM, ERM~II and Euro column; automatically include text
% change monthly abbrevations in R, not only local change but more; something like monthly abbrevations
% spalten rechtszentriert

% heavy increase in variance both countries exactly around EURO introduction 
% interesting thing: both were allready in a currency union (the belgish--luxembourg union)
\begin{longtable}{llrrr}
\hline
Country & Segment & Mean & Variance & Skewness  \\
\hline
<<echo=FALSE, results=tex>>=
writeLines(unlist(lapply(c(2, 13), format_moments)))
@
\end{longtable}

\end{frame}




\begin{frame}
\frametitle{Italy and Spain}

\vspace*{-0.8cm}


\begin{center}
<<itaspa, fig=TRUE, height=5, width=8>>=
trellis.par.set(theme = standard.theme(color = FALSE))
print(xyplot(cbind(100*diff(log(na.omit(HICP[, "Italy"]))), 100*diff(log(na.omit(HICP[, "Spain"])))), xlab="Time", ylab="", main="", screens=list("Italy", "Spain"), ylim=c(-2,2)))
@
\end{center}
\end{frame}



\begin{frame}
\frametitle{Italy and Spain}
% jesus explanation: less frequent fiscal shocks during consolidation period --> verify via government expenditures
% identical break dates
% now lower mean than in the 90s 
% after Dec 2000, almost 2 years after EURO heavy increase in volatility (very similar to Belgium and Luxembourg)
% Italy and Spain: commitment led to less frequent fiscal shocks 
\begin{longtable}{llrrr}
\hline
Country & Segment & Mean & Variance & Skewness \\
\hline
<<echo=FALSE, results=tex>>=
writeLines(unlist(lapply(c(12, 19), format_moments)))
@
\end{longtable}

\end{frame}




\begin{frame}
\frametitle{Ireland}
% deflationary effects of financial crisis clearly visible

\vspace*{-0.9cm}

\begin{center}
<<ireland, fig=TRUE, height=4, width=8>>=
plot(100*diff(log(na.omit(HICP[, "Ireland"]))), main="Ireland", ylab="", xlab ="Time", ylim=c(-2,2))
@
\end{center}

\vspace*{-0.6cm}

{
\small
\begin{longtable}{llrrr}
\hline
Country & Segment & Mean & Variance & Skewness \\
\hline
<<echo=FALSE, results=tex>>=
writeLines(unlist(lapply(c(11), format_moments)))
@
\end{longtable}
}

\end{frame}


\begin{frame}
\frametitle{No Change Countries}
% could be looking much better

\vspace*{-0.8cm}

\begin{center}
<<nochange, fig=TRUE, height=5, width=8>>=
trellis.par.set(theme = standard.theme(color = FALSE))
print(xyplot(cbind(100*diff(log(na.omit(HICP[, "Finland"]))), 100*diff(log(na.omit(HICP[, "Greece"]))), 100*diff(log(na.omit(HICP[, "Netherlands"])))), xlab="Time", ylab="", main="", screens=list("Finland", "Greece", "Netherlands"), ylim=c(-2.7,2.7)))
@
\end{center}
\end{frame}


\begin{frame}
\frametitle{No Change Countries}
% most interesting country: greece (extremely high variance, looks almost like a result of a random number seed 
\begin{longtable}{llrrr}
\hline
Country & Segment & Mean & Variance & Skewness  \\
\hline
<<echo=FALSE, results=tex>>=
writeLines(unlist(lapply(c(9,14,6), format_moments)))
@
\end{longtable}
\end{frame}



% 1-Austria 2 Belgium 3 CzechRepublic 4 Denmark 5 Estonia  6 Finland 7 France 8 Germany 9 Greece 10 Hungary 11 Ireland
% 12 Italy 13 Luxemburg 14 Netherlands 15 Poland 16 Portugal 17 Slovakia  18 Slovenia  19 Spain 20 Sweden 21 UnitedKingdom





\subsection{Conclusion}
\begin{frame}
\frametitle{Conclusion}

\begin{itemize}
% include some more

\item Stabilizing Effect of EURO?
% mention eastern european countries like Slovenia
\item Overall lowering in mean inflation rates
\item Overall increase in volatility
% possibly due to change in definitions or data collection
% why? discuss with participants; some fluctuation is natural but is there any good reason for this?
% delve into problematic of the countrries
\end{itemize}
\end{frame}

\subsubsection{HICP}
\begin{frame}
\frametitle{HICP}
% put at the end to be ready to show when asked but not include in beginning as to avoid confusion

First step: local sub-index of a specific price collected item $R_{iy}^t$:
% for each city y from all its outlets j, by use of the geometric mean of all prices collected from the outlets
\begin{eqnarray}
R_{iy}^t & = & \frac{(\prod_{j=1}^n p_{iyj}^t)^{1/n}}{(\prod_{j=1}^n p_{iyj}^0)^{1/n}} \nonumber
\end{eqnarray}

Second step: sub-index for whole country $R_i^t$:
% weighted mean of the subindices of this item for all cities
\begin{eqnarray}
R_i^t & = & \sum_{y=1}^m R_{iy}^t G_y \nonumber
\end{eqnarray}
% where G_y is the population weight
% this R_i^t is then weighted again: say food is part of HICP and chocolate is part of food, chocolate is weighted into overall food index
\begin{eqnarray}
R_h^{t,T} = R_h^{12,T-1} \left[ \frac{\sum_{i=1}^q w_i^T R_i^t/R_i^{12,T-1}}{\sum_{i=1}^q w_i^T} \right] \nonumber
\end{eqnarray}
% where q is the number of collected items in the food basket


Third step: weighted average of all included individual subindexes:
\begin{eqnarray}
HICP_t & = & \sum_{i=1}^n \gamma_i R_h^{t,T} \nonumber
\end{eqnarray}
% where gamma_i is some weight attached to food
% so the HICP is: a weighted average (HICP_t) of a weighted average (R_i^t) of a weighted average R_{iy}^t
% source: www.statistics.gr/portal/page/portal/ESYE/PAGE-themes?p_param=A0515&r_param=DKT90&y_param=MT&mytabs=0 the HICP Methodology
\end{frame}


% to show left and right skewed gl - distribution
\begin{frame}
\frametitle{GL: Skewness}
\begin{center}
<<glrl, fig=TRUE, height=5, width=8>>=
x <- -40:40/10
plot(x, dglogis(x, 0, 1, 2), type = "l", lty = 3,
  xlab = "y", ylab = expression(f(group("", y, "|"), 0, 1, delta)))
lines(x, dglogis(x, 0, 1, 1), type = "l", lty = 1)
lines(x, dglogis(x, 0, 1, 1/2), type = "l", lty = 2)
legend("topleft", expression(delta == 2, delta == 1, delta == 0.5),
  lty = c(3, 1, 2), bty = "n")
@
\end{center}
\end{frame}


\end{document}

